#!/usr/bin/env python3
"""
LookOnChain æ–‡ç« æŠ“å–åˆ†æå™¨
æ¯æ—¥å®šæ—¶æŠ“å– LookOnChain æœ€æ–°æ–‡ç« ï¼Œç¿»è¯‘ä¸ºä¸­æ–‡å¹¶ç”Ÿæˆ Hugo æ–‡ç« 
è¿è¡Œæ—¶é—´ï¼šæ¯æ—¥åŒ—äº¬æ—¶é—´18:00 (UTC 10:00) å’Œ 00:00 (UTC 16:00)
"""

import os
import sys
import datetime
from typing import List, Dict

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„ï¼Œç¡®ä¿èƒ½å¯¼å…¥æ¨¡å—
sys.path.insert(0, os.path.dirname(__file__))

# åœ¨ GitHub Actions ç¯å¢ƒå¤–å°è¯•åŠ è½½ .env.local æ–‡ä»¶
if not os.getenv('GITHUB_ACTIONS'):
    env_local_path = os.path.join(os.path.dirname(__file__), '.env.local')
    if os.path.exists(env_local_path):
        try:
            with open(env_local_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#') and '=' in line:
                        key, value = line.split('=', 1)
                        # åªæœ‰å½“ç¯å¢ƒå˜é‡ä¸å­˜åœ¨æ—¶æ‰è®¾ç½®
                        if not os.getenv(key.strip()):
                            os.environ[key.strip()] = value.strip()
        except Exception as e:
            print(f"âš ï¸ è­¦å‘Š: æ— æ³•åŠ è½½ .env.local æ–‡ä»¶: {e}")

from lookonchain.enhanced_scraper import EnhancedLookOnChainScraper
from lookonchain.enhanced_processor import EnhancedArticleProcessor
from lookonchain.config import OPENAI_API_KEY


class LookOnChainAnalyzer:
    """LookOnChain æ–‡ç« åˆ†æå™¨ä¸»ç±»"""
    
    def __init__(self, openai_api_key: str = None):
        self.openai_api_key = openai_api_key or OPENAI_API_KEY
        
        # åˆå§‹åŒ–å¢å¼ºç»„ä»¶
        self.scraper = EnhancedLookOnChainScraper()
        self.processor = EnhancedArticleProcessor(self.openai_api_key)
        
        print("ğŸš€ LookOnChain åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def run_daily_analysis(self) -> Dict[str, any]:
        """æ‰§è¡Œæ¯æ—¥åˆ†æä»»åŠ¡"""
        print(f"\nğŸ•• å¼€å§‹æ‰§è¡Œ LookOnChain æ¯æ—¥åˆ†æä»»åŠ¡ - {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        try:
            # æ˜¾ç¤ºå†å²ç»Ÿè®¡
            print("\n" + "="*50)
            print("ğŸ“Š å†å²æ–‡ç« ç»Ÿè®¡")
            print("="*50)
            self.processor.print_history_statistics()
            
            # æ­¥éª¤1: çˆ¬å–æœ€æ–°æ–‡ç« 
            print("\n" + "="*50)
            print("ğŸ“° æ­¥éª¤1: çˆ¬å–æœ€æ–° LookOnChain æ–‡ç« ")
            print("="*50)
            
            raw_articles = self.scraper.scrape_latest_articles()
            if not raw_articles:
                return {
                    "success": False,
                    "error": "æœªèƒ½çˆ¬å–åˆ°ä»»ä½•æ–‡ç« ",
                    "stage": "scraping"
                }
            
            print(f"âœ… æˆåŠŸçˆ¬å– {len(raw_articles)} ç¯‡æœ€æ–°æ–‡ç« ")
            
            # æ­¥éª¤2: å¤„ç†æ–‡ç« ï¼ˆç¿»è¯‘ + AIæ‘˜è¦ + å»é‡ï¼‰
            print("\n" + "="*50)
            print("ğŸ”„ æ­¥éª¤2: å¤„ç†æ–‡ç« ï¼ˆç¿»è¯‘ + AIæ‘˜è¦ + å»é‡ï¼‰")
            print("="*50)
            
            processed_articles = self.processor.process_articles_batch(raw_articles)
            
            if not processed_articles:
                return {
                    "success": False,
                    "error": "æ‰€æœ‰æ–‡ç« å¤„ç†å‡å¤±è´¥æˆ–é‡å¤",
                    "failed_articles": len(raw_articles),
                    "stage": "processing"
                }
            
            # æ­¥éª¤3: ç”ŸæˆHugoæ–‡ç« 
            print("\n" + "="*50)
            print("ğŸ“„ æ­¥éª¤3: ç”Ÿæˆ Hugo æ–‡ç« ")
            print("="*50)
            
            # è¿™é‡Œéœ€è¦è°ƒç”¨ç°æœ‰çš„æ–‡ç« ç”Ÿæˆå™¨
            # æš‚æ—¶ç®€åŒ–å¤„ç†ï¼Œç›´æ¥ä¿å­˜å¤„ç†åçš„æ–‡ç« 
            generation_result = self._save_processed_articles(processed_articles)
            
            # æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
            result = {
                "success": generation_result["success"],
                "scrapped_articles": len(raw_articles),
                "processed_articles": len(processed_articles),
                "unique_articles": len(processed_articles),
                "generated_articles": generation_result.get("generated_files", []),
                "api_stats": self.processor.get_api_statistics(),
                "message": generation_result["message"],
                "execution_time": datetime.datetime.now().isoformat(),
                "stage": "completed"
            }
            
            # å¦‚æœæœ‰é”™è¯¯ï¼Œæ·»åŠ åˆ°ç»“æœä¸­
            if not generation_result["success"]:
                result["error"] = generation_result["message"]
            
            return result
            
        except Exception as e:
            return {
                "success": False,
                "error": f"æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}",
                "stage": "execution",
                "execution_time": datetime.datetime.now().isoformat()
            }
    
    def _save_processed_articles(self, processed_articles: List[Dict]) -> Dict[str, any]:
        """ä¿å­˜å¤„ç†åçš„æ–‡ç« ä¸ºHugoæ ¼å¼"""
        try:
            import os
            from datetime import datetime
            
            # ç¡®ä¿å†…å®¹ç›®å½•å­˜åœ¨
            content_dir = "../content/posts"
            os.makedirs(content_dir, exist_ok=True)
            
            generated_files = []
            
            for i, article in enumerate(processed_articles):
                try:
                    # ç”Ÿæˆæ–‡ä»¶å
                    safe_title = "".join(c for c in article['title'][:50] if c.isalnum() or c in (' ', '-', '_')).rstrip()
                    safe_title = safe_title.replace(' ', '-')
                    timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')
                    filename = f"lookonchain-{timestamp}-{i+1}-{safe_title}.md"
                    filepath = os.path.join(content_dir, filename)
                    
                    # ç”ŸæˆHugoæ ¼å¼å†…å®¹
                    hugo_content = self._generate_hugo_content(article)
                    
                    # ä¿å­˜æ–‡ä»¶
                    with open(filepath, 'w', encoding='utf-8') as f:
                        f.write(hugo_content)
                    
                    generated_files.append(filepath)
                    print(f"âœ… ä¿å­˜æ–‡ç« : {filename}")
                    
                except Exception as e:
                    print(f"âŒ ä¿å­˜æ–‡ç« å¤±è´¥: {e}")
                    continue
            
            return {
                "success": True,
                "generated_files": generated_files,
                "message": f"æˆåŠŸç”Ÿæˆ {len(generated_files)} ç¯‡æ–‡ç« "
            }
            
        except Exception as e:
            return {
                "success": False,
                "message": f"ä¿å­˜æ–‡ç« å¤±è´¥: {str(e)}"
            }
    
    def _generate_hugo_content(self, article: Dict) -> str:
        """ç”ŸæˆHugoæ ¼å¼çš„å†…å®¹"""
        from datetime import datetime
        
        # ç”Ÿæˆæ ‡ç­¾
        tags = ['LookOnChain', 'é“¾ä¸Šæ•°æ®', 'åŠ å¯†è´§å¸åˆ†æ']
        if 'summary' in article and article['summary']:
            tags.append('AIæ‘˜è¦')
        
        # ç”Ÿæˆfrontmatter
        frontmatter = {
            "title": article['title'],
            "description": article.get('summary', '')[:200] + '...' if len(article.get('summary', '')) > 200 else article.get('summary', ''),
            "date": datetime.now().isoformat(),
            "tags": tags,
            "categories": ["é“¾ä¸Šæ•°æ®åˆ†æ"],
            "keywords": ["LookOnChainåˆ†æ", "é“¾ä¸Šæ•°æ®è¿½è¸ª", "AIæ‘˜è¦"],
            "author": "ERIC",
            "showToc": True,
            "TocOpen": False,
            "draft": False,
            "slug": f"lookonchain-{datetime.now().strftime('%Y%m%d-%H%M%S')}"
        }
        
        # ç”ŸæˆYAML frontmatter
        yaml_frontmatter = "---\n"
        for key, value in frontmatter.items():
            if isinstance(value, list):
                yaml_frontmatter += f"{key}:\n"
                for item in value:
                    yaml_frontmatter += f"  - {item}\n"
            else:
                yaml_frontmatter += f"{key}: {value}\n"
        yaml_frontmatter += "---\n\n"
        
        # ç”Ÿæˆæ­£æ–‡
        content = yaml_frontmatter
        
        # æ·»åŠ AIæ‘˜è¦
        if article.get('summary'):
            content += f"## ğŸ¤– AIæ‘˜è¦\n\n{article['summary']}\n\n"
        
        # æ·»åŠ åŸæ–‡ç¿»è¯‘
        content += f"## ğŸ“ åŸæ–‡ç¿»è¯‘\n\n{article['content']}\n\n"
        
        # æ·»åŠ åŸæ–‡é“¾æ¥
        content += f"---\n\n"
        content += f"**åŸæ–‡é“¾æ¥**: [{article.get('original_title', article['title'])}]({article['url']})\n\n"
        content += f"**æ•°æ®æ¥æº**: [LookOnChain](https://www.lookonchain.com)\n\n"
        content += f"**å¤„ç†æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
        
        return content
    
    def print_summary(self, result: Dict[str, any]):
        """æ‰“å°æ‰§è¡Œç»“æœæ‘˜è¦"""
        print("\n" + "="*60)
        print("ğŸ“Š LookOnChain åˆ†æä»»åŠ¡æ‰§è¡Œæ‘˜è¦")
        print("="*60)
        
        if result["success"]:
            print(f"âœ… ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ")
            print(f"ğŸ“° çˆ¬å–æ–‡ç« æ•°: {result.get('scrapped_articles', 0)}")
            print(f"ğŸ”„ å¤„ç†æ–‡ç« æ•°: {result.get('processed_articles', 0)}")
            print(f"ğŸ†” å»é‡åæ–‡ç« æ•°: {result.get('unique_articles', 0)}")
            print(f"ğŸ“„ ç”Ÿæˆæ–‡ç« æ•°: {len(result.get('generated_articles', []))}")
            print(f"ğŸ’¬ ç»“æœä¿¡æ¯: {result.get('message', '')}")
            
            if result.get('generated_articles'):
                print(f"\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
                for file_path in result['generated_articles']:
                    print(f"   â€¢ {os.path.basename(file_path)}")
            
            # æ˜¾ç¤ºAPIä½¿ç”¨ç»Ÿè®¡
            if result.get('api_stats'):
                stats = result['api_stats']
                print(f"\nğŸ¤– APIä½¿ç”¨ç»Ÿè®¡:")
                print(f"   ğŸ”¤ ç¿»è¯‘è°ƒç”¨: {stats.get('translation_calls', 0)} æ¬¡")
                print(f"   ğŸ“ æ‘˜è¦è°ƒç”¨: {stats.get('summary_calls', 0)} æ¬¡")
                print(f"   âŒ å¤±è´¥è°ƒç”¨: {stats.get('failed_calls', 0)} æ¬¡")
                print(f"   ğŸ“Š æˆåŠŸç‡: {stats.get('success_rate', 0):.1%}")
        else:
            print(f"âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥")
            print(f"ğŸ›‘ é”™è¯¯é˜¶æ®µ: {result.get('stage', 'unknown')}")
            print(f"â— é”™è¯¯ä¿¡æ¯: {result.get('error', 'Unknown error')}")
        
        print(f"â° æ‰§è¡Œæ—¶é—´: {result.get('execution_time', 'Unknown')}")
        print("="*60)


def main():
    """ä¸»å‡½æ•°"""
    
    print("ğŸŒ… LookOnChain æ¯æ—¥æ–‡ç« åˆ†æå™¨å¯åŠ¨")
    print(f"â° å½“å‰æ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # æ£€æŸ¥APIå¯†é’¥
    openai_api_key = OPENAI_API_KEY
    if not openai_api_key:
        print("âŒ é”™è¯¯: æœªè®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        print("ğŸ’¡ è¯·è®¾ç½®ç¯å¢ƒå˜é‡æˆ–åœ¨ scripts/.env.local æ–‡ä»¶ä¸­é…ç½®")
        sys.exit(1)
    
    if not os.getenv('GITHUB_ACTIONS'):
        print(f"âœ… OpenAI API Key å·²é…ç½®: {openai_api_key[:8]}...")
    
    # åˆ›å»ºåˆ†æå™¨å¹¶æ‰§è¡Œä»»åŠ¡
    analyzer = LookOnChainAnalyzer(openai_api_key)
    result = analyzer.run_daily_analysis()
    
    # æ‰“å°ç»“æœæ‘˜è¦
    analyzer.print_summary(result)
    
    # æ ¹æ®æ‰§è¡Œç»“æœè®¾ç½®é€€å‡ºç 
    if result["success"]:
        print("\nğŸ‰ ä»»åŠ¡å®Œæˆï¼")
        sys.exit(0)
    else:
        print("\nğŸ’¥ ä»»åŠ¡å¤±è´¥ï¼")
        sys.exit(1)


if __name__ == "__main__":
    main()