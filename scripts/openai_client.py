"""
OpenAIå…¼å®¹æ¥å£ç»Ÿä¸€å®¢æˆ·ç«¯æ¨¡å—
æ”¯æŒModelScopeç­‰OpenAIå…¼å®¹çš„APIæœåŠ¡
ä¿æŒé«˜å†…èšä½è€¦åˆè®¾è®¡ï¼Œéµå¾ªKISSåŸåˆ™
"""

import os
import time
from typing import Optional, Dict, Any
from openai import OpenAI

try:
    from glm_logger import GLMLogger as OriginalGLMLogger
    
    # æ‰©å±•åŸå§‹GLMLoggerï¼Œæ·»åŠ statså±æ€§ä»¥ä¿æŒå…¼å®¹æ€§
    class GLMLogger(OriginalGLMLogger):
        def __init__(self, log_dir: str = "logs"):
            super().__init__(log_dir)
            self.stats = {
                "total_calls": 0, 
                "successful_calls": 0, 
                "failed_calls": 0, 
                "total_tokens": 0, 
                "prompt_tokens": 0, 
                "completion_tokens": 0
            }
        
        def get_daily_stats(self):
            return self.stats
            
except ImportError:
    # å¦‚æœglm_loggerä¸å­˜åœ¨ï¼Œåˆ›å»ºç®€åŒ–ç‰ˆæœ¬
    class GLMLogger:
        def __init__(self, log_dir: str = "logs"):
            self.stats = {
                "total_calls": 0, 
                "successful_calls": 0, 
                "failed_calls": 0, 
                "total_tokens": 0, 
                "prompt_tokens": 0, 
                "completion_tokens": 0
            }
        
        def get_daily_stats(self):
            return self.stats


class OpenAIClientWrapper:
    """
    OpenAIå…¼å®¹æ¥å£å®¢æˆ·ç«¯åŒ…è£…å™¨
    ç»Ÿä¸€å¤„ç†æ‰€æœ‰OpenAIå…¼å®¹çš„APIè°ƒç”¨ï¼ŒåŒ…å«æ—¥å¿—è®°å½•åŠŸèƒ½
    """
    
    def __init__(self, api_key: str, base_url: str, model: str, logger: Optional[GLMLogger] = None):
        """
        åˆå§‹åŒ–OpenAIå…¼å®¹å®¢æˆ·ç«¯
        
        Args:
            api_key: APIå¯†é’¥
            base_url: APIåŸºç¡€URL
            model: æ¨¡å‹åç§°
            logger: å¯é€‰çš„æ—¥å¿—è®°å½•å™¨
        """
        self.api_key = api_key
        self.base_url = base_url
        self.model = model
        self.logger = logger or GLMLogger()
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        self.client = OpenAI(
            api_key=api_key,
            base_url=base_url
        )
    
    def chat_completions_create(self, **kwargs) -> Any:
        """
        åˆ›å»ºèŠå¤©å®Œæˆè¯·æ±‚çš„ç»Ÿä¸€æ¥å£
        è‡ªåŠ¨è®°å½•APIè°ƒç”¨ç»Ÿè®¡
        
        Returns:
            OpenAI ChatCompletionå“åº”å¯¹è±¡
        """
        # ç¡®ä¿ä½¿ç”¨é…ç½®çš„æ¨¡å‹ï¼ˆå¦‚æœæ²¡æœ‰æŒ‡å®šï¼‰
        if 'model' not in kwargs:
            kwargs['model'] = self.model
        
        try:
            # è®°å½•APIè°ƒç”¨å¼€å§‹
            start_time = time.time()
            self.logger.stats["total_calls"] += 1
            
            # å‘èµ·APIè¯·æ±‚
            response = self.client.chat.completions.create(**kwargs)
            
            # è®°å½•æˆåŠŸè°ƒç”¨
            self.logger.stats["successful_calls"] += 1
            
            # è®°å½•tokenä½¿ç”¨æƒ…å†µ
            if hasattr(response, 'usage') and response.usage:
                self.logger.stats["total_tokens"] += response.usage.total_tokens or 0
                self.logger.stats["prompt_tokens"] += response.usage.prompt_tokens or 0
                self.logger.stats["completion_tokens"] += response.usage.completion_tokens or 0
            
            # è®°å½•å“åº”æ—¶é—´
            response_time = time.time() - start_time
            
            return response
            
        except Exception as e:
            # è®°å½•å¤±è´¥è°ƒç”¨
            self.logger.stats["failed_calls"] += 1
            # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œä¿æŒåŸæœ‰é”™è¯¯å¤„ç†é€»è¾‘
            raise e
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–APIä½¿ç”¨ç»Ÿè®¡"""
        return self.logger.get_daily_stats()


def create_openai_client(
    api_key: Optional[str] = None,
    base_url: Optional[str] = None,
    model: Optional[str] = None,
    logger: Optional[GLMLogger] = None
) -> Optional[OpenAIClientWrapper]:
    """
    åˆ›å»ºOpenAIå…¼å®¹å®¢æˆ·ç«¯çš„å·¥å‚å‡½æ•°
    
    Args:
        api_key: APIå¯†é’¥ï¼Œé»˜è®¤ä»ç¯å¢ƒå˜é‡è·å–
        base_url: APIåŸºç¡€URLï¼Œé»˜è®¤ä½¿ç”¨ModelScope
        model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨Qwen2.5-Coder
        logger: æ—¥å¿—è®°å½•å™¨
    
    Returns:
        OpenAIClientWrapperå®ä¾‹æˆ–Noneï¼ˆåˆå§‹åŒ–å¤±è´¥æ—¶ï¼‰
    """
    # é»˜è®¤é…ç½®
    api_key = api_key or os.getenv('OPENAI_API_KEY')
    base_url = base_url or os.getenv('OPENAI_BASE_URL', 'https://api-inference.modelscope.cn/v1/')
    model = model or os.getenv('OPENAI_MODEL', 'Qwen/Qwen2.5-Coder-32B-Instruct')
    
    if not api_key:
        print("âŒ APIå¯†é’¥æœªè®¾ç½®ï¼Œè¯·è®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")
        return None
    
    if api_key in ['your_openai_api_key_here', 'your_api_key_here', '']:
        print("âŒ æ£€æµ‹åˆ°ç¤ºä¾‹APIå¯†é’¥ï¼Œè¯·è®¾ç½®æœ‰æ•ˆçš„OPENAI_API_KEY")
        return None
    
    try:
        client = OpenAIClientWrapper(
            api_key=api_key,
            base_url=base_url,
            model=model,
            logger=logger
        )
        print(f"âœ… OpenAIå…¼å®¹å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        print(f"   - åŸºç¡€URL: {base_url}")
        print(f"   - æ¨¡å‹: {model}")
        
        return client
        
    except Exception as e:
        print(f"âŒ OpenAIå…¼å®¹å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
        return None


def extract_content_from_response(response: Any, debug_context: str = "") -> Optional[str]:
    """
    ç¨³å¥åœ°ä»OpenAI APIå“åº”ä¸­æå–æ–‡æœ¬å†…å®¹
    æ”¯æŒå¤šç§å¯èƒ½çš„å“åº”æ ¼å¼ï¼Œæä¾›è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
    
    Args:
        response: APIå“åº”å¯¹è±¡
        debug_context: è°ƒè¯•ä¸Šä¸‹æ–‡ä¿¡æ¯
    
    Returns:
        æå–çš„æ–‡æœ¬å†…å®¹æˆ–None
    """
    if not response:
        print(f"âš ï¸ [{debug_context}] å“åº”ä¸ºç©º")
        return None
    
    try:
        # æ£€æŸ¥æ ‡å‡†OpenAIå“åº”æ ¼å¼
        if hasattr(response, 'choices') and response.choices:
            if not response.choices:
                print(f"âš ï¸ [{debug_context}] choicesä¸ºç©ºåˆ—è¡¨")
                return None
                
            choice = response.choices[0]
            
            # æ£€æŸ¥messageç»“æ„
            if hasattr(choice, 'message') and hasattr(choice.message, 'content'):
                content = choice.message.content
                if content and content.strip():
                    return content.strip()
                else:
                    print(f"âš ï¸ [{debug_context}] choices[0].message.content ä¸ºç©º")
        
        # å¦‚æœæ˜¯å­—å…¸æ ¼å¼
        if isinstance(response, dict):
            for key in ['content', 'text', 'output', 'result', 'choices']:
                if key in response and response[key]:
                    content = str(response[key]).strip()
                    if content:
                        print(f"âœ… [{debug_context}] ä»å­—å…¸ {key} æ‰¾åˆ°å†…å®¹")
                        return content
        
        # å°è¯•å…¶ä»–å¯èƒ½çš„å“åº”æ ¼å¼ (éMockå¯¹è±¡)
        if not str(type(response)).endswith("Mock'>"):
            for attr_name in ['content', 'text', 'output', 'result']:
                if hasattr(response, attr_name):
                    content = getattr(response, attr_name)
                    if content and str(content).strip():
                        print(f"âœ… [{debug_context}] ä» {attr_name} å­—æ®µæ‰¾åˆ°å†…å®¹")
                        return str(content).strip()
                    else:
                        print(f"âš ï¸ [{debug_context}] response.{attr_name} ä¸ºç©º")
        
        # è®°å½•å“åº”ç»“æ„ç”¨äºè°ƒè¯•
        if hasattr(response, '__dict__'):
            print(f"ğŸ” [{debug_context}] å“åº”ç»“æ„åˆ†æ:")
            for key, value in response.__dict__.items():
                if key not in ['_client', '_request_id']:
                    value_str = str(value)[:100] if len(str(value)) > 100 else str(value)
                    print(f"    {key}: {type(value)} = {value_str}")
        
        print(f"âŒ [{debug_context}] æ— æ³•æå–å†…å®¹")
        return None
        
    except Exception as e:
        print(f"âŒ [{debug_context}] è§£æå“åº”æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return None


# å‘åå…¼å®¹çš„åˆ«åï¼Œä¿æŒä¸ç°æœ‰ä»£ç çš„å…¼å®¹æ€§
GLMClientWrapper = OpenAIClientWrapper