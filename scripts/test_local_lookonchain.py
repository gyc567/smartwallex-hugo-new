#!/usr/bin/env python3
"""
æœ¬åœ°æµ‹è¯• LookOnChain åˆ†æå™¨
æµ‹è¯•æ–‡ç« ç”ŸæˆåŠŸèƒ½å¹¶ç¡®ä¿è¾“å‡ºåˆ°æ­£ç¡®ç›®å½•
"""

import os
import sys
import datetime

# ç¡®ä¿å¯ä»¥å¯¼å…¥æ¨¡å—
sys.path.insert(0, os.path.dirname(__file__))

from lookonchain.scraper import LookOnChainScraper
from lookonchain.translator import ChineseTranslator
from lookonchain.article_generator import ArticleGenerator


def create_test_articles():
    """åˆ›å»ºæµ‹è¯•æ–‡ç« æ•°æ®"""
    test_articles = [
        {
            'title': 'Whale Alert: 10,000 ETH Transferred to Binance',
            'url': 'https://www.lookonchain.com/test/article1',
            'summary': 'Large Ethereum whale moves significant funds to exchange',
            'content': '''A crypto whale has just transferred 10,000 ETH (approximately $25 million) to Binance exchange. This massive transfer was detected by our on-chain monitoring systems at block height 18,500,000. 

The whale address, which has been accumulating ETH for over 2 years, suddenly became active during the early Asian trading session. Market analysts are closely monitoring this movement as it could signal a potential major sell-off.

The transfer occurred when Ethereum was trading at $2,500, and similar large movements in the past have often preceded significant price volatility. The whale's wallet still contains over 50,000 ETH worth approximately $125 million.

On-chain data suggests this could be part of a larger institutional rebalancing strategy, as several other high-value addresses have shown similar activity patterns this week.''',
            'id': 'test001'
        },
        {
            'title': 'DeFi Flash Loan Attack Nets $2M in Profits',
            'url': 'https://www.lookonchain.com/test/article2', 
            'summary': 'Sophisticated flash loan exploit targets vulnerable DeFi protocol',
            'content': '''A sophisticated attacker successfully exploited a DeFi protocol using flash loans, netting approximately $2 million in profits within a single transaction. The attack targeted a newly launched yield farming protocol with over $50 million in total value locked.

The exploit utilized a complex multi-step process involving flash loans from Aave, price manipulation on decentralized exchanges, and arbitrage opportunities across different protocols. The entire attack was executed within one block, making it difficult to prevent.

Security researchers have identified the vulnerability as a classic price oracle manipulation attack. The protocol relied on a single price source, which the attacker manipulated using large trades on low-liquidity DEX pairs.

The attack has highlighted ongoing security challenges in the DeFi space, particularly for newer protocols with limited security audits. The affected protocol has since paused its smart contracts and is working on implementing additional security measures.''',
            'id': 'test002'
        },
        {
            'title': 'Bitcoin Mining Pool Consolidation Accelerates',
            'url': 'https://www.lookonchain.com/test/article3',
            'summary': 'Top 5 mining pools now control over 65% of Bitcoin hashrate',
            'content': '''Bitcoin mining pool consolidation has accelerated significantly, with the top 5 mining pools now controlling over 65% of the total network hashrate. This concentration has raised concerns about network decentralization and security.

Foundry USA leads with 28.5% of the hashrate, followed by AntPool with 18.2%, and F2Pool with 12.8%. The consolidation trend has intensified following recent mining difficulty adjustments and the ongoing bear market in cryptocurrency prices.

Smaller mining pools have struggled to remain competitive due to increased operational costs and reduced mining rewards. Many individual miners have migrated to larger pools to ensure more consistent payouts.

Industry experts warn that excessive mining pool consolidation could potentially threaten Bitcoin's decentralized nature. However, they note that individual miners can switch pools relatively easily if concerns arise about centralization.

The situation is being closely monitored by Bitcoin developers and the broader cryptocurrency community, with discussions ongoing about potential solutions to encourage mining decentralization.''',
            'id': 'test003'
        }
    ]
    
    return test_articles

def test_translation_mock(articles):
    """æ¨¡æ‹Ÿç¿»è¯‘è¿‡ç¨‹"""
    print("ğŸ”„ æ¨¡æ‹Ÿæ–‡ç« ç¿»è¯‘è¿‡ç¨‹...")
    
    translation_map = {
        'Whale Alert: 10,000 ETH Transferred to Binance': 'é²¸é±¼è­¦æŠ¥ï¼š10,000 ETHè½¬å…¥å¸å®‰äº¤æ˜“æ‰€',
        'DeFi Flash Loan Attack Nets $2M in Profits': 'DeFié—ªç”µè´·æ”»å‡»è·åˆ©200ä¸‡ç¾å…ƒ',
        'Bitcoin Mining Pool Consolidation Accelerates': 'æ¯”ç‰¹å¸çŸ¿æ± æ•´åˆåŠ é€Ÿï¼Œå»ä¸­å¿ƒåŒ–å¼•æ‹…å¿§'
    }
    
    translated_articles = []
    for article in articles:
        chinese_title = translation_map.get(article['title'], f"{article['title']} - ç¿»è¯‘æ ‡é¢˜")
        
        # æ¨¡æ‹Ÿä¸­æ–‡ç¿»è¯‘å†…å®¹
        chinese_content = f"""æ ¹æ®LookOnChainé“¾ä¸Šæ•°æ®ç›‘æµ‹ï¼Œ{chinese_title}æˆä¸ºå½“å‰å¸‚åœºå…³æ³¨ç„¦ç‚¹ã€‚

{article['content'][:200]}...ï¼ˆæ­¤å¤„ä¸ºå®Œæ•´ä¸­æ–‡ç¿»è¯‘å†…å®¹ï¼‰

è¿™ä¸€äº‹ä»¶åæ˜ äº†å½“å‰åŠ å¯†è´§å¸å¸‚åœºçš„é‡è¦åŠ¨æ€ï¼Œå€¼å¾—æŠ•èµ„è€…å¯†åˆ‡å…³æ³¨ã€‚é“¾ä¸Šæ•°æ®æ˜¾ç¤ºï¼Œç±»ä¼¼çš„å¤§é¢è½¬è´¦å¾€å¾€é¢„ç¤ºç€å¸‚åœºçš„é‡è¦å˜åŒ–ã€‚

æˆ‘ä»¬å°†æŒç»­ç›‘æ§ç›¸å…³åœ°å€çš„æ´»åŠ¨æƒ…å†µï¼Œä¸ºè¯»è€…æä¾›æœ€æ–°çš„å¸‚åœºåˆ†æå’ŒæŠ•èµ„å»ºè®®ã€‚"""

        summary = f"æœ¬æ–‡æ·±å…¥åˆ†æäº†{chinese_title}çš„å¸‚åœºå½±å“ï¼ŒåŸºäºLookOnChainä¸“ä¸šé“¾ä¸Šæ•°æ®ç›‘æµ‹ï¼Œä¸ºæŠ•èµ„è€…æä¾›é‡è¦çš„å¸‚åœºæ´å¯Ÿã€‚"
        
        translated_article = {
            'original_title': article['title'],
            'chinese_title': chinese_title,
            'original_content': article['content'],
            'chinese_content': chinese_content,
            'summary': summary,
            'url': article['url'],
            'id': article['id'],
            'original_summary': article['summary']
        }
        translated_articles.append(translated_article)
        print(f"   âœ… å·²ç¿»è¯‘: {chinese_title}")
    
    return translated_articles

def test_local_generation():
    """æµ‹è¯•æœ¬åœ°æ–‡ç« ç”ŸæˆåŠŸèƒ½"""
    print("ğŸš€ å¼€å§‹æœ¬åœ° LookOnChain æ–‡ç« ç”Ÿæˆæµ‹è¯•")
    print(f"â° æµ‹è¯•æ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # è®¾ç½®æ­£ç¡®çš„è¾“å‡ºç›®å½•
    current_dir = os.path.dirname(os.path.dirname(__file__))  # ä¸Šä¸€çº§ç›®å½•
    output_dir = os.path.join(current_dir, 'content', 'posts')
    
    print(f"ğŸ“ ç›®æ ‡è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ğŸ“ ç›®å½•æ˜¯å¦å­˜åœ¨: {os.path.exists(output_dir)}")
    
    if not os.path.exists(output_dir):
        print("âŒ ç›®æ ‡ç›®å½•ä¸å­˜åœ¨ï¼Œåˆ›å»ºç›®å½•...")
        os.makedirs(output_dir, exist_ok=True)
    
    # æ­¥éª¤1: åˆ›å»ºæµ‹è¯•æ•°æ®
    print("\n" + "="*50)
    print("ğŸ“° æ­¥éª¤1: åˆ›å»ºæµ‹è¯•æ–‡ç« æ•°æ®")
    print("="*50)
    
    raw_articles = create_test_articles()
    print(f"âœ… åˆ›å»ºäº† {len(raw_articles)} ç¯‡æµ‹è¯•æ–‡ç« ")
    for i, article in enumerate(raw_articles, 1):
        print(f"   {i}. {article['title']}")
    
    # æ­¥éª¤2: æ¨¡æ‹Ÿç¿»è¯‘
    print("\n" + "="*50)
    print("ğŸ”„ æ­¥éª¤2: æ¨¡æ‹Ÿæ–‡ç« ç¿»è¯‘")
    print("="*50)
    
    translated_articles = test_translation_mock(raw_articles)
    print(f"âœ… ç¿»è¯‘å®Œæˆ {len(translated_articles)} ç¯‡æ–‡ç« ")
    
    # æ­¥éª¤3: ç”ŸæˆHugoæ–‡ç« 
    print("\n" + "="*50)
    print("ğŸ“„ æ­¥éª¤3: ç”Ÿæˆ Hugo æ–‡ç« åˆ°ç›®æ ‡ç›®å½•")
    print("="*50)
    
    generator = ArticleGenerator()
    
    # é‡è¦ï¼šä¿®æ”¹è¾“å‡ºç›®å½•ä¸ºå®é™…çš„ content/posts ç›®å½•
    generated_files = []
    
    for i, article in enumerate(translated_articles, 1):
        print(f"\nğŸ“ ç”Ÿæˆæ–‡ç«  {i}: {article['chinese_title']}")
        
        # ä½¿ç”¨æ­£ç¡®çš„è¾“å‡ºç›®å½•
        file_path = generator.create_hugo_article(article, output_dir)
        if file_path:
            generated_files.append(file_path)
            print(f"   âœ… æˆåŠŸç”Ÿæˆ: {file_path}")
            
            # éªŒè¯æ–‡ä»¶æ˜¯å¦çœŸçš„åˆ›å»ºäº†
            if os.path.exists(file_path):
                file_size = os.path.getsize(file_path)
                print(f"   ğŸ“Š æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
            else:
                print(f"   âŒ æ–‡ä»¶åˆ›å»ºå¤±è´¥: {file_path}")
        else:
            print(f"   âŒ ç”Ÿæˆå¤±è´¥")
    
    # æ­¥éª¤4: éªŒè¯ç»“æœ
    print("\n" + "="*50)
    print("âœ… æ­¥éª¤4: éªŒè¯ç”Ÿæˆç»“æœ")
    print("="*50)
    
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ğŸ“ ç”Ÿæˆæ–‡ä»¶æ•°: {len(generated_files)}")
    
    if generated_files:
        print("\nğŸ“‹ ç”Ÿæˆçš„æ–‡ä»¶åˆ—è¡¨:")
        for file_path in generated_files:
            filename = os.path.basename(file_path)
            print(f"   â€¢ {filename}")
        
        # æ˜¾ç¤ºç¬¬ä¸€ä¸ªæ–‡ä»¶çš„éƒ¨åˆ†å†…å®¹
        print(f"\nğŸ“„ æ–‡ä»¶å†…å®¹ç¤ºä¾‹ ({os.path.basename(generated_files[0])}):")
        print("-" * 60)
        with open(generated_files[0], 'r', encoding='utf-8') as f:
            content = f.read()
            lines = content.split('\n')
            # æ˜¾ç¤ºå‰30è¡Œ
            for line in lines[:30]:
                print(line)
            if len(lines) > 30:
                print("...")
                print(f"ï¼ˆæ–‡ä»¶å…±{len(lines)}è¡Œï¼Œä»…æ˜¾ç¤ºå‰30è¡Œï¼‰")
        print("-" * 60)
    
    # æ£€æŸ¥ç›®æ ‡ç›®å½•ä¸­çš„æ‰€æœ‰LookOnChainæ–‡ä»¶
    print(f"\nğŸ” æ£€æŸ¥ç›®å½•ä¸­æ‰€æœ‰ LookOnChain ç›¸å…³æ–‡ä»¶:")
    all_files = os.listdir(output_dir)
    lookonchain_files = [f for f in all_files if 'lookonchain' in f.lower()]
    
    if lookonchain_files:
        print(f"   æ‰¾åˆ° {len(lookonchain_files)} ä¸ª LookOnChain æ–‡ä»¶:")
        for f in sorted(lookonchain_files):
            print(f"   â€¢ {f}")
    else:
        print("   æœªæ‰¾åˆ°ä»»ä½• LookOnChain æ–‡ä»¶")
    
    # æœ€ç»ˆæ€»ç»“
    print("\n" + "="*60)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“")
    print("="*60)
    print(f"âœ… æµ‹è¯•æ–‡ç« : {len(raw_articles)} ç¯‡")
    print(f"âœ… ç¿»è¯‘æ–‡ç« : {len(translated_articles)} ç¯‡")
    print(f"âœ… ç”Ÿæˆæ–‡ä»¶: {len(generated_files)} ä¸ª")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"âœ… ç›®å½•éªŒè¯: {'é€šè¿‡' if os.path.exists(output_dir) else 'å¤±è´¥'}")
    
    if generated_files:
        print("ğŸ‰ æœ¬åœ°æµ‹è¯•å®Œå…¨æˆåŠŸï¼æ–‡ç« å·²ç”Ÿæˆåˆ°æ­£ç¡®ç›®å½•")
        
        # è¯¢é—®æ˜¯å¦ä¿ç•™æ–‡ä»¶
        keep_files = input("\næ˜¯å¦ä¿ç•™ç”Ÿæˆçš„æµ‹è¯•æ–‡ä»¶ï¼Ÿ(y/N): ").lower().strip()
        if keep_files != 'y':
            print("\nğŸ§¹ æ¸…ç†æµ‹è¯•æ–‡ä»¶...")
            for file_path in generated_files:
                try:
                    os.remove(file_path)
                    print(f"   âœ… å·²åˆ é™¤: {os.path.basename(file_path)}")
                except Exception as e:
                    print(f"   âŒ åˆ é™¤å¤±è´¥: {os.path.basename(file_path)} - {e}")
            print("âœ… æ¸…ç†å®Œæˆ")
        else:
            print("ğŸ“ æµ‹è¯•æ–‡ä»¶å·²ä¿ç•™")
    else:
        print("âŒ æµ‹è¯•å¤±è´¥ï¼šæœªèƒ½ç”Ÿæˆä»»ä½•æ–‡ä»¶")
    
    print("\nğŸ‘‹ æµ‹è¯•ç»“æŸ")

if __name__ == "__main__":
    test_local_generation()