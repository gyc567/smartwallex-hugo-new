#!/usr/bin/env python3
"""
GLM-4.5 APIæ—¥å¿—æŸ¥çœ‹å·¥å…·
ç”¨äºæŸ¥çœ‹å’Œåˆ†æGLM APIè°ƒç”¨æ—¥å¿—
"""

import json
import argparse
import datetime
import os
from typing import Dict, Any, List
from glm_logger import GLMLogger

def format_timestamp(timestamp_str: str) -> str:
    """æ ¼å¼åŒ–æ—¶é—´æˆ³"""
    try:
        dt = datetime.datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
        return dt.strftime('%H:%M:%S')
    except:
        return timestamp_str

def print_stats(stats: Dict[str, Any]):
    """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
    print(f"\nğŸ“Š GLM-4.5 APIè°ƒç”¨ç»Ÿè®¡ ({stats['date']})")
    print("=" * 50)
    
    if "error" in stats:
        print(f"âŒ é”™è¯¯: {stats['error']}")
        return
    
    print(f"æ€»è°ƒç”¨æ¬¡æ•°: {stats['total_calls']}")
    print(f"æˆåŠŸè°ƒç”¨: {stats['successful_calls']}")
    print(f"å¤±è´¥è°ƒç”¨: {stats['failed_calls']}")
    print(f"æˆåŠŸç‡: {(stats['successful_calls'] / max(1, stats['total_calls']) * 100):.1f}%")
    
    print(f"\nğŸ”¢ Tokenä½¿ç”¨æƒ…å†µ:")
    print(f"æ€»Tokenæ¶ˆè€—: {stats['total_tokens']:,}")
    print(f"è¾“å…¥Token: {stats['prompt_tokens']:,}")
    print(f"è¾“å‡ºToken: {stats['completion_tokens']:,}")
    
    if stats['total_tokens'] > 0:
        avg_tokens = stats['total_tokens'] / max(1, stats['successful_calls'])
        print(f"å¹³å‡æ¯æ¬¡è°ƒç”¨Token: {avg_tokens:.1f}")
    
    print(f"\nğŸ“ˆ å„åŠŸèƒ½è°ƒç”¨ç»Ÿè®¡:")
    if stats['functions']:
        for func_name, func_stats in stats['functions'].items():
            tokens = func_stats['tokens']
            calls = func_stats['calls']
            avg = tokens / max(1, calls)
            print(f"  â€¢ {func_name}: {calls}æ¬¡è°ƒç”¨, {tokens:,}ä¸ªtokens (å¹³å‡{avg:.1f}/æ¬¡)")
    else:
        print("  æ— åŠŸèƒ½è°ƒç”¨è®°å½•")
    
    if stats['errors']:
        print(f"\nâŒ é”™è¯¯è®°å½• ({len(stats['errors'])}ä¸ª):")
        for error in stats['errors'][-5:]:  # åªæ˜¾ç¤ºæœ€è¿‘5ä¸ªé”™è¯¯
            time_str = format_timestamp(error['timestamp'])
            print(f"  â€¢ {time_str} - {error['function']}: {error['error']}")

def print_detailed_logs(date: str, limit: int = 10, function_filter: str = None):
    """æ‰“å°è¯¦ç»†æ—¥å¿—"""
    logger = GLMLogger()
    detail_log_file = os.path.join(logger.log_dir, f"glm_api_details_{date}.jsonl")
    
    if not os.path.exists(detail_log_file):
        print(f"âŒ æ‰¾ä¸åˆ°æ—¥æœŸ {date} çš„è¯¦ç»†æ—¥å¿—æ–‡ä»¶")
        return
    
    print(f"\nğŸ“‹ è¯¦ç»†è°ƒç”¨æ—¥å¿— ({date})")
    print("=" * 80)
    
    count = 0
    try:
        with open(detail_log_file, 'r', encoding='utf-8') as f:
            logs = []
            for line in f:
                entry = json.loads(line.strip())
                if function_filter and function_filter not in entry['function']:
                    continue
                logs.append(entry)
            
            # æ˜¾ç¤ºæœ€è¿‘çš„æ—¥å¿—
            for entry in logs[-limit:]:
                count += 1
                time_str = format_timestamp(entry['timestamp'])
                func_name = entry['function']
                success = "âœ…" if entry['response']['success'] else "âŒ"
                
                print(f"\n[{count}] {time_str} {success} {func_name}")
                
                # æ˜¾ç¤ºè¯·æ±‚ä¿¡æ¯
                req = entry['request']
                if req.get('messages'):
                    user_msg = ""
                    for msg in req['messages']:
                        if msg.get('role') == 'user':
                            user_msg = msg.get('content', '')[:100] + "..."
                            break
                    print(f"    ğŸ“ è¯·æ±‚: {user_msg}")
                
                print(f"    ğŸ”§ å‚æ•°: model={req.get('model', 'N/A')}, temp={req.get('temperature', 'N/A')}, max_tokens={req.get('max_tokens', 'N/A')}")
                
                # æ˜¾ç¤ºå“åº”ä¿¡æ¯
                if entry['response']['success']:
                    content = entry['response'].get('content', '')
                    print(f"    ğŸ“¤ å“åº”: {content[:100]}...")
                else:
                    print(f"    âŒ é”™è¯¯: {entry['response'].get('error', 'Unknown error')}")
                
                # æ˜¾ç¤ºTokenä½¿ç”¨
                usage = entry.get('usage', {})
                if usage:
                    print(f"    ğŸ”¢ Tokens: {usage.get('total_tokens', 0)} (è¾“å…¥:{usage.get('prompt_tokens', 0)}, è¾“å‡º:{usage.get('completion_tokens', 0)})")
                
    except Exception as e:
        print(f"âŒ è¯»å–æ—¥å¿—æ–‡ä»¶æ—¶å‡ºé”™: {e}")

def list_available_dates():
    """åˆ—å‡ºå¯ç”¨çš„æ—¥å¿—æ—¥æœŸ"""
    logger = GLMLogger()
    if not os.path.exists(logger.log_dir):
        print("âŒ æ—¥å¿—ç›®å½•ä¸å­˜åœ¨")
        return
    
    print("ğŸ“… å¯ç”¨çš„æ—¥å¿—æ—¥æœŸ:")
    log_files = [f for f in os.listdir(logger.log_dir) if f.startswith('glm_api_details_') and f.endswith('.jsonl')]
    
    if not log_files:
        print("  æ— å¯ç”¨æ—¥å¿—æ–‡ä»¶")
        return
    
    dates = []
    for filename in log_files:
        date_part = filename.replace('glm_api_details_', '').replace('.jsonl', '')
        dates.append(date_part)
    
    dates.sort(reverse=True)
    for date in dates:
        size = os.path.getsize(os.path.join(logger.log_dir, f'glm_api_details_{date}.jsonl'))
        print(f"  â€¢ {date} ({size} bytes)")

def export_to_csv(date: str, output_file: str = None):
    """å¯¼å‡ºæ—¥å¿—åˆ°CSVæ–‡ä»¶"""
    import csv
    
    logger = GLMLogger()
    detail_log_file = os.path.join(logger.log_dir, f"glm_api_details_{date}.jsonl")
    
    if not os.path.exists(detail_log_file):
        print(f"âŒ æ‰¾ä¸åˆ°æ—¥æœŸ {date} çš„æ—¥å¿—æ–‡ä»¶")
        return
    
    if not output_file:
        output_file = f"glm_api_logs_{date}.csv"
    
    try:
        with open(detail_log_file, 'r', encoding='utf-8') as infile, \
             open(output_file, 'w', newline='', encoding='utf-8') as outfile:
            
            writer = csv.writer(outfile)
            writer.writerow([
                'timestamp', 'function', 'success', 'model', 'temperature', 
                'max_tokens', 'prompt_tokens', 'completion_tokens', 'total_tokens', 
                'request_content', 'response_content', 'error'
            ])
            
            for line in infile:
                entry = json.loads(line.strip())
                
                # æå–ç”¨æˆ·è¾“å…¥å†…å®¹
                request_content = ""
                for msg in entry['request'].get('messages', []):
                    if msg.get('role') == 'user':
                        request_content = msg.get('content', '')[:200]
                        break
                
                response_content = entry['response'].get('content', '')[:200]
                error = entry['response'].get('error', '')
                usage = entry.get('usage', {})
                
                writer.writerow([
                    entry['timestamp'],
                    entry['function'],
                    entry['response']['success'],
                    entry['request'].get('model', ''),
                    entry['request'].get('temperature', ''),
                    entry['request'].get('max_tokens', ''),
                    usage.get('prompt_tokens', 0),
                    usage.get('completion_tokens', 0),
                    usage.get('total_tokens', 0),
                    request_content,
                    response_content,
                    error
                ])
        
        print(f"âœ… å·²å¯¼å‡ºæ—¥å¿—åˆ°: {output_file}")
        
    except Exception as e:
        print(f"âŒ å¯¼å‡ºCSVæ—¶å‡ºé”™: {e}")

def main():
    parser = argparse.ArgumentParser(description='GLM-4.5 APIæ—¥å¿—æŸ¥çœ‹å·¥å…·')
    parser.add_argument('--date', '-d', help='æŸ¥çœ‹æŒ‡å®šæ—¥æœŸçš„æ—¥å¿— (YYYY-MM-DD)ï¼Œé»˜è®¤ä¸ºä»Šå¤©')
    parser.add_argument('--stats', '-s', action='store_true', help='æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯')
    parser.add_argument('--logs', '-l', action='store_true', help='æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—')
    parser.add_argument('--limit', type=int, default=10, help='é™åˆ¶æ˜¾ç¤ºçš„æ—¥å¿—æ¡æ•°ï¼Œé»˜è®¤10')
    parser.add_argument('--function', '-f', help='è¿‡æ»¤æŒ‡å®šå‡½æ•°çš„æ—¥å¿—')
    parser.add_argument('--list-dates', action='store_true', help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ—¥å¿—æ—¥æœŸ')
    parser.add_argument('--export-csv', help='å¯¼å‡ºåˆ°CSVæ–‡ä»¶')
    
    args = parser.parse_args()
    
    if args.list_dates:
        list_available_dates()
        return
    
    # ç¡®å®šè¦æŸ¥çœ‹çš„æ—¥æœŸ
    if args.date:
        target_date = args.date
    else:
        target_date = datetime.datetime.now().strftime('%Y-%m-%d')
    
    logger = GLMLogger()
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if args.stats or (not args.logs and not args.export_csv):
        stats = logger.get_daily_stats(target_date)
        print_stats(stats)
    
    # æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—
    if args.logs:
        print_detailed_logs(target_date, args.limit, args.function)
    
    # å¯¼å‡ºCSV
    if args.export_csv:
        export_to_csv(target_date, args.export_csv)

if __name__ == "__main__":
    main()