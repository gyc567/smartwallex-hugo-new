"""
æ–‡ç« ç¿»è¯‘å’Œæ€»ç»“æ¨¡å—
ä½¿ç”¨ GLM API å°†è‹±æ–‡æ–‡ç« ç¿»è¯‘ä¸ºä¸­æ–‡å¹¶ç”Ÿæˆæ‘˜è¦
"""

import json
import time
import sys
import os
from typing import Dict, Tuple, Optional
from openai import OpenAI

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ä»¥å¯¼å…¥ glm_logger
sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))
try:
    from glm_logger import GLMLogger, GLMClientWrapper
except ImportError:
    # å¦‚æœ glm_logger ä¸å­˜åœ¨ï¼Œåˆ›å»ºç®€åŒ–ç‰ˆæœ¬
    print("Warning: glm_logger not found, using simplified version")
    
    class GLMLogger:
        def __init__(self):
            self.stats = {"total_calls": 0, "successful_calls": 0, "failed_calls": 0, 
                         "total_tokens": 0, "prompt_tokens": 0, "completion_tokens": 0}
        
        def get_daily_stats(self):
            return self.stats
    
    class GLMClientWrapper:
        def __init__(self, api_key, base_url, logger):
            self.client = OpenAI(api_key=api_key, base_url=base_url)
            self.logger = logger
        
        def chat_completions_create(self, **kwargs):
            try:
                response = self.client.chat.completions.create(**kwargs)
                self.logger.stats["total_calls"] += 1
                self.logger.stats["successful_calls"] += 1
                if hasattr(response, 'usage') and response.usage:
                    self.logger.stats["total_tokens"] += response.usage.total_tokens
                    self.logger.stats["prompt_tokens"] += response.usage.prompt_tokens
                    self.logger.stats["completion_tokens"] += response.usage.completion_tokens
                return response
            except Exception as e:
                self.logger.stats["total_calls"] += 1
                self.logger.stats["failed_calls"] += 1
                raise e
from .config import (
    GLM_API_KEY, GLM_API_BASE, GLM_MODEL,
    TRANSLATION_TEMPERATURE, SUMMARY_TEMPERATURE,
    MAX_TOKENS_TRANSLATION, MAX_TOKENS_SUMMARY
)


class ChineseTranslator:
    """ä¸­æ–‡ç¿»è¯‘å’Œæ€»ç»“ç”Ÿæˆå™¨"""
    
    def __init__(self, glm_api_key: str = None):
        self.api_key = glm_api_key or GLM_API_KEY
        self.client = None
        self.logger = None
        
        if self.api_key:
            try:
                # åˆå§‹åŒ–GLMæ—¥å¿—è®°å½•å™¨
                self.logger = GLMLogger()
                
                # ä½¿ç”¨åŒ…è£…å®¢æˆ·ç«¯ï¼Œè‡ªåŠ¨è®°å½•APIè°ƒç”¨
                self.client = GLMClientWrapper(
                    api_key=self.api_key,
                    base_url=GLM_API_BASE,
                    logger=self.logger
                )
                print("âœ… GLMç¿»è¯‘å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"âŒ GLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
                self.client = None
                self.logger = None
        else:
            print("âŒ ç¼ºå°‘GLM APIå¯†é’¥ï¼Œç¿»è¯‘åŠŸèƒ½å°†ä¸å¯ç”¨")
    
    def translate_to_chinese(self, english_content: str, title: str = "") -> Optional[str]:
        """å°†è‹±æ–‡å†…å®¹ç¿»è¯‘ä¸ºä¸­æ–‡"""
        if not self.client:
            print("âŒ ç¿»è¯‘å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return None
        
        try:
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŠ å¯†è´§å¸å’ŒåŒºå—é“¾é¢†åŸŸç¿»è¯‘ä¸“å®¶ã€‚è¯·å°†æä¾›çš„è‹±æ–‡æ–‡ç« ç¿»è¯‘ä¸ºè‡ªç„¶æµç•…çš„ä¸­æ–‡ï¼Œè¦æ±‚ï¼š

1. ä¿æŒä¸“ä¸šæœ¯è¯­çš„å‡†ç¡®æ€§ï¼ˆå¦‚DeFiã€NFTã€åŒºå—é“¾ç­‰ï¼‰
2. ç¿»è¯‘è¦ç¬¦åˆä¸­æ–‡è¡¨è¾¾ä¹ æƒ¯
3. ä¿ç•™åŸæ–‡çš„ç»“æ„å’Œè¯­è°ƒ
4. å¯¹äºä¸“ä¸šæœ¯è¯­ï¼Œé¦–æ¬¡å‡ºç°æ—¶å¯ä»¥ä¿ç•™è‹±æ–‡åŸæ–‡åœ¨æ‹¬å·ä¸­
5. æ•°å­—ã€æ—¶é—´ã€ä»·æ ¼ç­‰ä¿¡æ¯ä¿æŒåŸæ ·
6. ä¿æŒæ®µè½ç»“æ„

è¯·ç›´æ¥è¾“å‡ºç¿»è¯‘åçš„ä¸­æ–‡å†…å®¹ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–è¯´æ˜ã€‚"""

            user_prompt = f"""è¯·ç¿»è¯‘ä»¥ä¸‹å…³äºåŠ å¯†è´§å¸/åŒºå—é“¾çš„è‹±æ–‡æ–‡ç« ï¼š

æ ‡é¢˜ï¼š{title}

å†…å®¹ï¼š
{english_content}"""

            print("ğŸ”„ æ­£åœ¨ç¿»è¯‘ä¸ºä¸­æ–‡...")
            
            completion = self.client.chat_completions_create(
                model=GLM_MODEL,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=TRANSLATION_TEMPERATURE,
                max_tokens=MAX_TOKENS_TRANSLATION
            )
            
            chinese_content = completion.choices[0].message.content.strip()
            print(f"âœ… ç¿»è¯‘å®Œæˆï¼Œé•¿åº¦: {len(chinese_content)} å­—ç¬¦")
            return chinese_content
            
        except Exception as e:
            print(f"âŒ ç¿»è¯‘å¤±è´¥: {e}")
            return None
    
    def generate_summary(self, chinese_content: str, title: str = "") -> Optional[str]:
        """ç”Ÿæˆä¸­æ–‡æ–‡ç« æ‘˜è¦"""
        if not self.client:
            print("âŒ æ‘˜è¦ç”Ÿæˆå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return None
        
        try:
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŠ å¯†è´§å¸å†…å®¹åˆ†æå¸ˆã€‚è¯·ä¸ºæä¾›çš„ä¸­æ–‡æ–‡ç« ç”Ÿæˆä¸€ä¸ªç²¾ç‚¼çš„æ‘˜è¦ï¼Œè¦æ±‚ï¼š

1. æ‘˜è¦é•¿åº¦æ§åˆ¶åœ¨200-300å­—
2. çªå‡ºæ–‡ç« çš„æ ¸å¿ƒè¦ç‚¹å’Œå…³é”®ä¿¡æ¯
3. ä¿æŒå®¢è§‚ä¸­æ€§çš„è¯­è°ƒ
4. åŒ…å«é‡è¦çš„æ•°æ®ã€äº‹ä»¶æˆ–è¶‹åŠ¿
5. é€‚åˆä½œä¸ºæ–‡ç« çš„å¼€å¤´æ®µè½
6. è¯­è¨€è¦ä¸“ä¸šä¸”æ˜“æ‡‚

è¯·ç›´æ¥è¾“å‡ºæ‘˜è¦å†…å®¹ï¼Œä¸è¦æ·»åŠ "æ‘˜è¦ï¼š"ç­‰æ ‡é¢˜ã€‚"""

            user_prompt = f"""è¯·ä¸ºä»¥ä¸‹ä¸­æ–‡æ–‡ç« ç”Ÿæˆæ‘˜è¦ï¼š

æ ‡é¢˜ï¼š{title}

æ–‡ç« å†…å®¹ï¼š
{chinese_content}"""

            print("ğŸ“ æ­£åœ¨ç”Ÿæˆæ–‡ç« æ‘˜è¦...")
            
            completion = self.client.chat_completions_create(
                model=GLM_MODEL,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=SUMMARY_TEMPERATURE,
                max_tokens=MAX_TOKENS_SUMMARY
            )
            
            summary = completion.choices[0].message.content.strip()
            print(f"âœ… æ‘˜è¦ç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(summary)} å­—ç¬¦")
            return summary
            
        except Exception as e:
            print(f"âŒ æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
            return None
    
    def translate_title(self, english_title: str) -> Optional[str]:
        """ç¿»è¯‘æ–‡ç« æ ‡é¢˜"""
        if not self.client:
            print("âŒ æ ‡é¢˜ç¿»è¯‘å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return None
        
        try:
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŠ å¯†è´§å¸å†…å®¹ç¿»è¯‘ä¸“å®¶ã€‚è¯·å°†è‹±æ–‡æ ‡é¢˜ç¿»è¯‘ä¸ºå¸å¼•äººçš„ä¸­æ–‡æ ‡é¢˜ï¼Œè¦æ±‚ï¼š

1. ä¿æŒåŸæ„å‡†ç¡®
2. ç¬¦åˆä¸­æ–‡è¡¨è¾¾ä¹ æƒ¯
3. é€‚åˆä½œä¸ºæ–°é—»æˆ–åˆ†ææ–‡ç« æ ‡é¢˜
4. é•¿åº¦é€‚ä¸­ï¼ˆ20-50å­—ï¼‰
5. ä¿ç•™å…³é”®æœ¯è¯­çš„ä¸“ä¸šæ€§

è¯·ç›´æ¥è¾“å‡ºç¿»è¯‘åçš„ä¸­æ–‡æ ‡é¢˜ã€‚"""

            user_prompt = f"è¯·ç¿»è¯‘ä»¥ä¸‹è‹±æ–‡æ ‡é¢˜ï¼š{english_title}"

            print("ğŸ·ï¸ æ­£åœ¨ç¿»è¯‘æ ‡é¢˜...")
            
            completion = self.client.chat_completions_create(
                model=GLM_MODEL,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=TRANSLATION_TEMPERATURE,
                max_tokens=200
            )
            
            chinese_title = completion.choices[0].message.content.strip()
            # æ¸…ç†å¯èƒ½çš„å¼•å·
            chinese_title = chinese_title.strip('"\'')
            print(f"âœ… æ ‡é¢˜ç¿»è¯‘å®Œæˆ: {chinese_title}")
            return chinese_title
            
        except Exception as e:
            print(f"âŒ æ ‡é¢˜ç¿»è¯‘å¤±è´¥: {e}")
            return None
    
    def process_article(self, article_data: Dict[str, str]) -> Optional[Dict[str, str]]:
        """å¤„ç†å®Œæ•´æ–‡ç« ï¼šç¿»è¯‘æ ‡é¢˜ã€å†…å®¹å¹¶ç”Ÿæˆæ‘˜è¦"""
        print(f"\nğŸ”„ å¼€å§‹å¤„ç†æ–‡ç« : {article_data.get('title', 'Untitled')[:50]}...")
        
        # ç¿»è¯‘æ ‡é¢˜
        chinese_title = self.translate_title(article_data['title'])
        if not chinese_title:
            print("âŒ æ ‡é¢˜ç¿»è¯‘å¤±è´¥ï¼Œè·³è¿‡è¯¥æ–‡ç« ")
            return None
        
        # ç­‰å¾…é¿å…APIé™åˆ¶
        time.sleep(1)
        
        # ç¿»è¯‘å†…å®¹
        chinese_content = self.translate_to_chinese(
            article_data['content'], 
            article_data['title']
        )
        if not chinese_content:
            print("âŒ å†…å®¹ç¿»è¯‘å¤±è´¥ï¼Œè·³è¿‡è¯¥æ–‡ç« ")
            return None
        
        # ç­‰å¾…é¿å…APIé™åˆ¶
        time.sleep(1)
        
        # ç”Ÿæˆæ‘˜è¦
        summary = self.generate_summary(chinese_content, chinese_title)
        if not summary:
            print("âŒ æ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ‘˜è¦")
            summary = f"æœ¬æ–‡åˆ†æäº†{chinese_title}ç›¸å…³çš„é“¾ä¸Šæ•°æ®å’Œå¸‚åœºåŠ¨æ€ã€‚"
        
        processed_article = {
            'original_title': article_data['title'],
            'chinese_title': chinese_title,
            'original_content': article_data['content'],
            'chinese_content': chinese_content,
            'summary': summary,
            'url': article_data.get('url', ''),
            'id': article_data.get('id', ''),
            'original_summary': article_data.get('summary', '')
        }
        
        print(f"âœ… æ–‡ç« å¤„ç†å®Œæˆ: {chinese_title}")
        return processed_article
    
    def get_api_usage_stats(self) -> Dict[str, any]:
        """è·å–APIä½¿ç”¨ç»Ÿè®¡"""
        if self.logger:
            return self.logger.get_daily_stats()
        return {"error": "æ—¥å¿—è®°å½•å™¨æœªåˆå§‹åŒ–"}