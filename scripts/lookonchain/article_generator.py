"""
Hugo æ–‡ç« ç”Ÿæˆå™¨æ¨¡å—
å°†ç¿»è¯‘åçš„æ–‡ç« ç”Ÿæˆç¬¦åˆ Hugo æ ¼å¼çš„ markdown æ–‡ä»¶
"""

import os
import datetime
import json
import re
from typing import Dict, List, Optional, Set
from .config import (
    AUTHOR_INFO, DEFAULT_TAGS, DEFAULT_CATEGORIES, DEFAULT_KEYWORDS,
    DATA_DIR, LOOKONCHAIN_HISTORY_FILE
)


class ArticleGenerator:
    """Hugo æ–‡ç« ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.ensure_data_directory()
        self.history_file = LOOKONCHAIN_HISTORY_FILE
    
    def ensure_data_directory(self):
        """ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨"""
        os.makedirs(DATA_DIR, exist_ok=True)
    
    def load_article_history(self) -> Set[str]:
        """åŠ è½½å·²ç”Ÿæˆçš„æ–‡ç« å†å²è®°å½•"""
        try:
            if os.path.exists(self.history_file):
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return set(data.get('generated_articles', []))
            return set()
        except Exception as e:
            print(f"âš ï¸ åŠ è½½æ–‡ç« å†å²è®°å½•å¤±è´¥: {e}")
            return set()
    
    def save_article_history(self, article_ids: Set[str]):
        """ä¿å­˜å·²ç”Ÿæˆçš„æ–‡ç« å†å²è®°å½•"""
        try:
            data = {
                'last_updated': datetime.datetime.now().isoformat(),
                'total_articles': len(article_ids),
                'generated_articles': list(article_ids)
            }
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print(f"âœ… å·²ä¿å­˜ {len(article_ids)} ä¸ªæ–‡ç« è®°å½•")
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜æ–‡ç« å†å²è®°å½•å¤±è´¥: {e}")
    
    def is_article_generated(self, article_id: str, generated_articles: Set[str]) -> bool:
        """æ£€æŸ¥æ–‡ç« æ˜¯å¦å·²ç»ç”Ÿæˆè¿‡"""
        return article_id in generated_articles
    
    def generate_filename(self, chinese_title: str, article_id: str) -> str:
        """ç”Ÿæˆæ–‡ä»¶å"""
        # ä»ä¸­æ–‡æ ‡é¢˜ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
        filename_base = re.sub(r'[^\w\u4e00-\u9fa5\-]', '-', chinese_title)
        filename_base = re.sub(r'-+', '-', filename_base).strip('-')
        
        # é™åˆ¶æ–‡ä»¶åé•¿åº¦
        if len(filename_base) > 50:
            filename_base = filename_base[:50]
        
        # æ·»åŠ æ—¥æœŸå’ŒIDç¡®ä¿å”¯ä¸€æ€§
        today = datetime.datetime.now().strftime('%Y-%m-%d')
        filename = f"lookonchain-{filename_base}-{today}-{article_id[:8]}.md"
        
        return filename
    
    def generate_article_tags(self, chinese_content: str, chinese_title: str) -> List[str]:
        """åŸºäºå†…å®¹ç”Ÿæˆç›¸å…³æ ‡ç­¾"""
        tags = DEFAULT_TAGS.copy()
        
        # å…³é”®è¯æ£€æµ‹
        content_lower = (chinese_content + chinese_title).lower()
        
        keyword_mapping = {
            'defi': ['DeFi', 'å»ä¸­å¿ƒåŒ–é‡‘è'],
            'nft': ['NFT', 'æ•°å­—æ”¶è—å“'],
            'bitcoin': ['Bitcoin', 'BTC', 'æ¯”ç‰¹å¸'],
            'ethereum': ['Ethereum', 'ETH', 'ä»¥å¤ªåŠ'],
            'whale': ['é²¸é±¼åœ°å€', 'å¤§æˆ·'],
            'exchange': ['äº¤æ˜“æ‰€', 'ä¸­å¿ƒåŒ–äº¤æ˜“'],
            'dao': ['DAO', 'å»ä¸­å¿ƒåŒ–ç»„ç»‡'],
            'token': ['ä»£å¸åˆ†æ', 'ä»£å¸ç»æµå­¦'],
            'mining': ['æŒ–çŸ¿', 'çŸ¿å·¥'],
            'staking': ['è´¨æŠ¼', 'æƒç›Šè¯æ˜']
        }
        
        for keyword, related_tags in keyword_mapping.items():
            if keyword in content_lower:
                tags.extend(related_tags)
        
        # å»é‡å¹¶é™åˆ¶æ•°é‡
        return list(set(tags))[:8]
    
    def generate_hugo_frontmatter(self, article: Dict[str, str]) -> str:
        """ç”ŸæˆHugoå‰ç½®matter"""
        
        now = datetime.datetime.now()
        date_str = now.strftime('%Y-%m-%dT%H:%M:%S+08:00')
        
        # å¤„ç†æ ‡é¢˜ä¸­çš„ç‰¹æ®Šå­—ç¬¦
        safe_title = article['chinese_title'].replace("'", "''").replace('"', '""')
        
        # ç”Ÿæˆæè¿°
        description = article['summary'][:150] + "..." if len(article['summary']) > 150 else article['summary']
        safe_description = description.replace("'", "''").replace('"', '""')
        
        # ç”Ÿæˆæ ‡ç­¾
        tags = self.generate_article_tags(article['chinese_content'], article['chinese_title'])
        tags_str = str(tags).replace("'", '"')  # ä½¿ç”¨åŒå¼•å·
        
        # ç”Ÿæˆå…³é”®è¯
        keywords = DEFAULT_KEYWORDS.copy()
        keywords.append(f"{article['chinese_title']}åˆ†æ")
        keywords_str = str(keywords).replace("'", '"')
        
        # ç”Ÿæˆåˆ†ç±»
        categories_str = str(DEFAULT_CATEGORIES).replace("'", '"')
        
        frontmatter = f"""+++
date = '{date_str}'
draft = false
title = '{safe_title}'
description = '{safe_description}'
summary = '{safe_description}'
tags = {tags_str}
categories = {categories_str}
keywords = {keywords_str}
author = '{AUTHOR_INFO["name"]}'
ShowToc = true
TocOpen = false
ShowReadingTime = true
ShowBreadCrumbs = true
ShowPostNavLinks = true
ShowWordCount = true
ShowShareButtons = true

[cover]
image = ""
alt = "LookOnChainé“¾ä¸Šæ•°æ®åˆ†æ"
caption = "æ·±åº¦è§£æåŒºå—é“¾é“¾ä¸Šæ•°æ®åŠ¨æ€"
relative = false
hidden = false
+++"""
        
        return frontmatter
    
    def generate_article_content(self, article: Dict[str, str]) -> str:
        """ç”Ÿæˆå®Œæ•´çš„æ–‡ç« å†…å®¹"""
        
        # æ–‡ç« æ‘˜è¦éƒ¨åˆ†
        content = f"""{{{{< alert >}}}}
**LookOnChainé“¾ä¸Šç›‘æ§**: {article['summary']}
{{{{< /alert >}}}}

{article['chinese_content']}

## ğŸ“Š æ•°æ®æ¥æºä¸åˆ†æ

æœ¬æ–‡åŸºäºLookOnChainå¹³å°çš„é“¾ä¸Šæ•°æ®åˆ†æç”Ÿæˆã€‚LookOnChainæ˜¯ä¸šç•Œé¢†å…ˆçš„åŒºå—é“¾æ•°æ®åˆ†æå¹³å°ï¼Œä¸“æ³¨äºè¿½è¸ªå’Œåˆ†æé“¾ä¸Šèµ„é‡‘æµåŠ¨ã€å¤§æˆ·è¡Œä¸ºç­‰å…³é”®ä¿¡æ¯ã€‚

### ğŸ”— ç›¸å…³é“¾æ¥
- **åŸæ–‡é“¾æ¥**: [{article.get('url', '#')}]({article.get('url', '#')})
- **LookOnChainå¹³å°**: [https://www.lookonchain.com/](https://www.lookonchain.com/)

### ğŸ“ˆ æŠ•èµ„é£é™©æç¤º
ä»¥ä¸Šå†…å®¹ä»…ä¸ºé“¾ä¸Šæ•°æ®åˆ†æï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚åŠ å¯†è´§å¸æŠ•èµ„å­˜åœ¨é«˜é£é™©ï¼Œä»·æ ¼æ³¢åŠ¨å‰§çƒˆï¼Œè¯·ç†æ€§æŠ•èµ„å¹¶åšå¥½é£é™©ç®¡ç†ã€‚æŠ•èµ„å‰è¯·å……åˆ†äº†è§£é¡¹ç›®åŸºæœ¬é¢ï¼Œä¸è¦æŠ•å…¥è¶…å‡ºæ‰¿å—èƒ½åŠ›çš„èµ„é‡‘ã€‚

---

## ğŸ“ å…³äºä½œè€…

**{AUTHOR_INFO['name']}** - {AUTHOR_INFO['title']}

### ğŸ”— è”ç³»æ–¹å¼ä¸å¹³å°

- **ğŸ“§ é‚®ç®±**: [{AUTHOR_INFO['email']}](mailto:{AUTHOR_INFO['email']})
- **ğŸ¦ Twitter**: [{AUTHOR_INFO['twitter']}](https://twitter.com/{AUTHOR_INFO['twitter'].replace('@', '')})
- **ğŸ’¬ å¾®ä¿¡**: {AUTHOR_INFO['wechat']}
- **ğŸ“± Telegram**: [{AUTHOR_INFO['telegram']}]({AUTHOR_INFO['telegram']})
- **ğŸ“¢ Telegramé¢‘é“**: [{AUTHOR_INFO['telegram_channel']}]({AUTHOR_INFO['telegram_channel']})
- **ğŸ‘¥ åŠ å¯†æƒ…æŠ¥TGç¾¤**: [{AUTHOR_INFO['telegram_group']}]({AUTHOR_INFO['telegram_group']})
- **ğŸ¥ YouTubeé¢‘é“**: [{AUTHOR_INFO['youtube']}]({AUTHOR_INFO['youtube']})

### ğŸŒ ç›¸å…³å¹³å°

- **ğŸ“Š åŠ å¯†è´§å¸ä¿¡æ¯èšåˆç½‘ç«™**: [{AUTHOR_INFO['website']}]({AUTHOR_INFO['website']})
- **ğŸ“– å…¬ä¼—å·**: {AUTHOR_INFO['wechat_public']}

*æ¬¢è¿å…³æ³¨æˆ‘çš„å„ä¸ªå¹³å°ï¼Œè·å–æœ€æ–°çš„åŠ å¯†è´§å¸å¸‚åœºåˆ†æå’ŒæŠ•èµ„æ´å¯Ÿï¼*"""
        
        return content
    
    def create_hugo_article(self, article: Dict[str, str], output_dir: str) -> Optional[str]:
        """åˆ›å»ºå®Œæ•´çš„Hugoæ–‡ç« æ–‡ä»¶"""
        try:
            # ç”Ÿæˆæ–‡ä»¶å
            filename = self.generate_filename(article['chinese_title'], article['id'])
            file_path = os.path.join(output_dir, filename)
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(output_dir, exist_ok=True)
            
            # ç”Ÿæˆå‰ç½®matter
            frontmatter = self.generate_hugo_frontmatter(article)
            
            # ç”Ÿæˆæ–‡ç« å†…å®¹
            content = self.generate_article_content(article)
            
            # ç»„åˆå®Œæ•´æ–‡ç« 
            full_article = f"{frontmatter}\n\n{content}\n"
            
            # å†™å…¥æ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(full_article)
            
            print(f"âœ… æ–‡ç« å·²ç”Ÿæˆ: {file_path}")
            return file_path
            
        except Exception as e:
            print(f"âŒ æ–‡ç« ç”Ÿæˆå¤±è´¥: {e}")
            return None
    
    def generate_daily_articles(self, processed_articles: List[Dict[str, str]]) -> Dict[str, any]:
        """ç”Ÿæˆå½“æ—¥çš„æ‰€æœ‰æ–‡ç« """
        if not processed_articles:
            return {"success": False, "message": "æ²¡æœ‰æ–‡ç« éœ€è¦ç”Ÿæˆ", "generated": 0}
        
        print(f"ğŸ“ å‡†å¤‡ç”Ÿæˆ {len(processed_articles)} ç¯‡æ–‡ç« ...")
        
        # åŠ è½½å†å²è®°å½•
        generated_articles = self.load_article_history()
        print(f"ğŸ“š å·²ç”Ÿæˆæ–‡ç« æ•°é‡: {len(generated_articles)}")
        
        # ç¡®å®šè¾“å‡ºç›®å½•
        current_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        output_dir = os.path.join(current_dir, 'content', 'posts')
        
        generated_count = 0
        generated_files = []
        newly_generated = set()
        
        for i, article in enumerate(processed_articles, 1):
            article_id = article['id']
            
            # æ£€æŸ¥æ˜¯å¦å·²ç”Ÿæˆ
            if self.is_article_generated(article_id, generated_articles):
                print(f"â­ï¸ è·³è¿‡å·²ç”Ÿæˆæ–‡ç«  {i}: {article['chinese_title'][:30]}...")
                continue
            
            print(f"\nğŸ“„ ç”Ÿæˆæ–‡ç«  {i}: {article['chinese_title'][:50]}...")
            
            # ç”Ÿæˆæ–‡ç« 
            file_path = self.create_hugo_article(article, output_dir)
            if file_path:
                generated_count += 1
                generated_files.append(file_path)
                newly_generated.add(article_id)
                print(f"âœ… æ–‡ç«  {i} ç”ŸæˆæˆåŠŸ")
            else:
                print(f"âŒ æ–‡ç«  {i} ç”Ÿæˆå¤±è´¥")
        
        # æ›´æ–°å†å²è®°å½•
        if newly_generated:
            all_generated = generated_articles.union(newly_generated)
            self.save_article_history(all_generated)
        
        result = {
            "success": generated_count > 0,
            "generated": generated_count,
            "total_processed": len(processed_articles),
            "files": generated_files,
            "newly_generated_ids": list(newly_generated)
        }
        
        if generated_count > 0:
            result["message"] = f"æˆåŠŸç”Ÿæˆ {generated_count} ç¯‡æ–‡ç« "
        else:
            result["message"] = "æ²¡æœ‰æ–°æ–‡ç« ç”Ÿæˆï¼ˆå¯èƒ½éƒ½å·²å­˜åœ¨ï¼‰"
        
        return result